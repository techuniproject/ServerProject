																																																																																																																																																																																														/*



      1. 페이징 메모리 관리 개요

	  [페이징 개념]

	 - 페이징은 프로세스의 주소 공간을 0번지부터 페이지로 불리는 고정 크기로 나누고 물리
	   메모리 역시 0번지부터 페이지와 동일한 크기로 분할하여, 프로세스의 각 페이지를 물리
	    메모리의 임의의 페이지에 분산 할당하는 메모리 관리 기법이다.
	 
	 - 물리 메모리에서 페이지 크기의 메모리 블록을 프레임(frame), 페이지 프레임 (page frame), 혹은
	    물리 페이지 (physical frame)이라고 부른다.
	 - 페이지는 대부분 4KB로 설정되지만, 시스템에 따라 8KB, 16KB로 설정되기도 함.

	 - 페이징 기법의 기본 이론은 프로세스의 주소 공간을 페이지 크기로 일률적으로 나누고 페이지 경계를 고려하지
	    않고 코드, 데이터, 힙을 연이어 배치한다.
	 - 그러므로 코드가 담긴 마지막 페이지에 데이터 영역이 시작되고 데이터 영역의 마지막 페이지 내에
	    힙 영역이 시작된다.
	 - 하지만, 실제 운영체제들은 코드, 데이터, 힙 등을 쉽게 관리하기 위해 데이터와 힙 영역이 새 페이지에서
	    시작하도록 배치한다.

	 - 물리 메모리가 프레임으로 분할되어 있고, 프로세스의 각 페이지가 페이지 테이블을 통해 물리 프레임에
	    매핑된다.
	 - 프로세스마다 페이지와 물리 프레임을 매핑하는 페이지 테이블이 존재하며, MMU 장치는 페이지 테이블을
	    이용하여 논리주소를 물리주소로 변환한다.

	 [페이지 우수성]

	  1) 구현이 쉽다
	   - 페이징은 메모리를 0번지부터 고정 크기의 페이지로 분할하기 때문에 세그먼테이션보다 이해하기 쉽고 구현하기 쉬움.
	  
	  2) 이식성이 높다(portable)
	   - 페이징은 CPU에 의존적이지 않기 때문에 다양한 컴퓨터 시스템에 동일한 방식으로 쉽게 구현 가능.

	  3) 융통성이 높다 (flexible)
	   - 시스템에 따라 혹은 응용에 따라 페이지 크기를 다르게 설정할 수 있다.
	   
	  4) 단편화
	   - 세그먼테이션에서 발생하는 외부 단편화가 없고, 홀 선택 알고리즘을 실행할 필요가 없어,
	      메모리 활용과 시간 오버헤드 면에서 훨씬 우수하다.
	   - 물론 내부 단편화가 발생하지만, 그 크기는 매우 작다.


	 [프로세스가 동적 할당 받을 때]

	  - 프로세스의 힙과 스택 영역은 프로세스의 실행 중에 피에지가 생기기도 하고 소멸되기도 하면서 계속 변한다.
	  - char* a = new char[200];
	  - 운영체제는 new char[200] 함수가 요청한 200바이트의 메모리를 할당하기 위해 먼저 프로세스의 힙 영역에
	     페이지를 할당(전 페이지를 모두 사용한 가정)
	  - 비어 있는 물리 프레임을 할당하여 프로세스 페이지 테이블의 항목에 프레임 번호를 기록하여 연결해줌.
	  - 이러면 *a를 하면 할당 받은 페이지에 기록하는데 CPU는 논리주소에 접근하는것 같지만, 실제로는
	     MMU에 의해 논리주소가 물리주소로(페이지 테이블을 거쳐) 변환하여 해당 물리 주소에 저장.

	 [시스템 호출시 프로세스의 페이지 테이블 활용]

	  - 프로세스 주소 공간 중 커널 페이지들을 물리 프레임에 매핑하는 프로세스 테이블 항목들도 존재한다.
	  - 프로세스 주소 공간에서 커널 페이지가 활용되는 경우는 프로세스가 시스템 호출을 하는 경우이다.
	  - 커널 코드 역시 논리 주소로 컴파일되어 있으며, 시스템 호출을 통해 커널 코드가 실행될 때
	    현재 프로세스의 페이지 테이블을 이용하여 물리 주소로 변환된다.
      - 커널도 논리 주소 기반 컴파일이어서 다른 프로세스가 같은 커널 코드를 호출할 때, 
	     결론적으로 페이지 테이블을 거쳐 같은 물리 주소의 커널 코드를 실행.
	  - 커널 코드는 단 하나의 물리 메모리 공간에 존재하기 때문.


	  2. 페이징의 주소 체계

	 [페이징의 논리 주소]

	  - 페이징을 사용하는 시스템에서는 프로세스의 논리 주소는 다음과 같이 페이지 번호와 옵셋으로 구성됨.
	  - 옵셋은 페이지 내에서의 상대 주소이고, 몇번째 바이트인지.
	  [논리주소] : [페이지 번호(p) , 옵셋(offset)]

	 [논리 주소의 물리 주소 변환]

	  - 페이지 테이블에는 프로세스의 모든 페이지에 대해 할당된 프레임 번호가 저장되기 때문에
	     특정 페이지를 페이지 테이블의 인덱스로 하여 페이지 테이블 항목을 찾으면 대응하는 프레임 번호를
		  얻음.
	  - 페이지 번호를 프레임 번호로 바꾸고, 옵셋을 그대로 사용하면 논리 주소를 물리 주소로 변환가능
	  -> 옵셋은 그대로 사용하는 이유는 논리 페이지나 물리 페이지 크기가 같으므로.
	  - 페이지 테이블도 물리 메모리에 저장되긴함.

	 [페이징 구현]

	  1) 하드웨어 지원
	   - PCU 칩 내에는 현재 실행중인 프로세스의 페이지 테이블이 적재된 물리 메모리 주소를 가진 레지스터,
	      PTBR(Page Table Base Register)이 필요하다.
	   - 이 레지스터의 값은 PCB에 저장되며, 프로세스가 스케줄되어 실행될 때 운영체제에 의해 CPU에 복귀한다.
	   - 또한 논리 주소를 물리 주소로 변환하기 위한 MMU 장치가 CPU칩에 패키징됨.

	  2) 운영체제 지원
	   - 운영체제는 물리 메모리의 빈 프레임 리스트를 생성하고 관리 유지하며, 메모리 프레임을 동적으로
	      할당/반환하는 기능과 이에 따라 페이지 테이블을 관리하는 기능을 가지고 있어야 한다.
	   - 또한 각 프로세스마다 페이지 테이블이 적재된 물리 메모리 주소를 PCB에 저장하고 프로세스가 스케줄되어
	      실행될 때마다 PCB로부터 페이지 테이블의 물리 주소를 CPU 내 PTBR 레지스터로 옮겨야 한다.
	
--------------------------------------------------------------------------------------------------------------------------------------------------------------

	
	2. 페이지 테이블의 문제점과 TLB

	  [페이지 테이블의 문제점]

	   - 페이징 기법은 단순하여 구현하기 쉬운 장점이 있는 반면, 페이지 테이블로 인한 성능 저하와
	      공간 낭비의 2가지 문제가 내재되어 있다.

	  1) 페이지 테이블은 몇 MB 수준으로 크기 때문에 CPU 칩 내에 둘 수 없어 메모리에 둔다.
	   
	   -> 그러므로 CPU가 메모리를 액세스할 때마다 페이지 테이블 액세스 1번, 데이터의 물리 메모리 액세스 1번으로
	       총 물리 메모리를 2번 액세스하여 프로세스의 실행 속도를 심각하게 저하시킨다.

	   - CPU가 메모리를 액세스할 때 논리 주소가 발생하고 MMU에 의해 논리 주소가 물리 주소로 바뀌어
	      주소 버스를 통해 출력된 후, CPU는 물리 메모리가 데이터 버스에 출력한 데이터를 가져가게 된다.
	   -> CPU의 이러한 메모리 액세스 과정에서 얼핏 물리 메모리가 1번만 액세스되는 것 같다.
	   -> 하지만, 이 과정에서 논리 주소를 물리 주소로 바꿀 때 페이지 테이블이 필요한데, 페이지 테이블이
	       물리 메모리에 존재하기 때문에 필요한 페이지 테이블 항목을 물리 메모리로부터 읽어오는 과정이 더 
		    필요하다는 사실이다.


	  2) 페이지 테이블의 낭비 문제이다.

	   -> 페이지 테이블의 크기는 프로세스의 최대 크기(주소 공간)에 맞추어 생성되지만, 실제 프로세스의
	       크기는 그에 못 미치기 때문에, 페이지 테이블의 많은 항목들이 사용되지 않는 채 비어 있는 메모리
		    낭비를 가져온다.
 
     [문제점 해결 방안]

	 [TLB를 이용한 2번의 물리 메모리 액세스 문제 해결]

	 - 논리 주소를 무릴 주소로 바꾸는 과정에서 페이지 테이블을 읽어 오는 과정을 없앤다면 프로그램의
	    실행 속도를 획기적으로 줄일 수 있다.

	 [TLB(Translation Look-aside Buffer)]

	 - TLB는 MMY 내에 두는 것으로 CPU가 최근에 액세스한 페이지 번호화 페이지가 적재된 프레임 번호의 쌍
	    을 저장하는 캐시 메모리이며 [페이지 번호 p, 프레임 번호 f]로 구성됨.
	 - TLB는 논리 주소를 물리 주소로 변환할 때 사용되므로 주소 변환용 캐시라고도 부른다.

	 - TLB 캐시에서 페이지 번호가 검색되는 방식이 일반 메모리와 많이 다르다.
	 - TLB는 논리 주소에 담긴 페이지 번호를 TLB 내의 각 항목에 걸쳐 하나씩 순차적으로 비교하지 않고,
	    모든 항목과 동시에 비교하여 단번에 프레임 번호를 출력한다.
	 - 번지를 사용하지 않고, 내용을 직접 비교하여 찾는 메모리라고 해서 TLB를 내용-주소화 기억 장치 혹은
	    연관 메모리라고도 부른다.

	 - 현재 상용 CPU 내에 사용되는 TLB의 경우, 항목의 개수는 64~1024개로 작은 편이다.
	 - 이것은 모든 항목들을 동시에 비교하는 하드웨어 회로를 필요로 하기 때문에 가격이 비싸고,
	    항목 수에 비례하여 회로가 늘어나서 CPU 내 공간 제약을 받을 수 밖에 없기 때문이다.
	 ->!! TLB의 크기가 작기 때문에 페이지 테이블 전체를 저장할 수 없고, 최근에 액세스한 소수의 페이지와
	    프레임의 번호를 저장하여 TLB의 활용성을 높인다.

	 [TLB를 활용한 메모리 액세스]
	
	질문) 그럼 페이지 테이블 워크가 물리메모리 접근 2번인데 캐시 미스가 더 성능이 안좋은 이유
	❗ 캐시 미스는 1번의 접근이지만, 그게 메모리로 가는 "진짜 값" 접근이라서 훨씬 느립니다.
	❗ 페이지 테이블 워크는 2~4번 접근해도 대부분은 캐시에서 걸리고, 하드웨어 최적화가 잘 되어 있어 덜 느립니다.
	
	 - 현재 대부분의 상용 CPU 칩은 TLB를 내장하고 있다.
	 - TLB를 사용하는 경우, TLB 히트가 발생하면 바로 주소 변환이 일어나므로 페이지 테이블을 액세스하지
	    않고 1번만 물리 메모리를 액세스한다.
	 - 즉 CPU의 메모리 액세스 시간을 반으로 줄인다. (TLB 히트 시)
	 - TLB를 활용하면 페이지 테이블을 읽는 횟수가 대폭 줄고 프로그램의 실행 속도는 대폭 향상된다.
	 - 배열이나 코드들은 순차적으로 액세스되는 경향을 보이기 때문에 이들은 액세스하는 동안 동일한 
	    페이지가 액세스될 가능성이 높다.
	 - 초기에 TLB 미스가 발생한 후 미스한 페이지 번호와 프레임 번호가 TLB 캐시에 삽입되므로 그 후부터는
	    거의 TLB 미스가 나지 않는다.

	 [TLB와 참조 지역성]

	 - TLB를 사용한다고 모든 프로그램의 실행 속도가 개선되는 것은 아님.
	 - 프로그램의 메모리 액세스 패턴에 따라 실행 속도가 달라진다.
	 - TLB는 순차 메모리 액세스 패턴을 가진 프로그램에게 매우 효과적이다.
	 - 프로그램은 실행되는 동안 짧은 시간 범위 내에 일정 구간의 메모리 영역을 반복 액세스하는 경향이 있음.
	 - 이 경향성을 참조의 지역성이라 하는데, 많은 반복문이 존재하므로 코드나 데이터가 아주 짧은 시간 내에
	    다시 액세스될 가능성이 매우 높음.
	 - 참조의 지역성은 공간에서도 나타나는데 지금 액세스되는 메모리의 주변 번지들이 가까운 미래에 액세스될
	    확률이 매우 높다.
	 - 배열 및 코드는 순차적으로 접근 및 실행되므로 현재 실행하는 다음 번지의 데이터나 명령이 액세스 및 접근됨.
	 
	 - 하지만,, 프로그램이 랜덤하게 메모리를 액세스할 경우, 참조의 지역성이 잘 형성되지 않기 때문에
	    TLB 미스가 자주 발생하고 페이지 테이블을 액세스하는 횟수 또한 많다
	 - 랜덤 메모리 액세스 패턴을 가진 응용프로그램이 TLB 사용으로 얻는 실행 속도 향상은 크지 않다.
	 
	 [TLB 성능과 TLB 도달 범위 - TLB reach / TLB coverage]

	 - TLB 성능은 TLB 히트율이며 프로그램의 실행 성능과 직결된다.
	 - TLB 히트율은 CPU의 메모리 액세스 횟수에 대한 TLB 히트 횟수의 비율이다.
	 - TLB의 성능은 TLB의 항목 수와 페이지의ㅣ 크기에 비례한다.
	 - TLB의 성능을 높이려면 TLB 항목 수를 늘리는 것으로 쉽게 해결되지만 비용이 상승하므로 절충점을 찾아야함.

	 - 다른 방법으로 페이지 크기가 클수록 TLB 히트율이 높아지고 프로그램의 실행 성능도 향상된다.
	 - 페이지 크기가 크면 내부 단편화가 증가하여 메모리가 낭비되는 단점이 있다.
	 - TLB 히트율과 내부 단편화는 이해득실 관계에 있으므로 선택의 문제이다.
	 - 페이지킈 크기는 디스크 입출력 성능 향상을 위해 커지는 추세이다.

	 - TLB 도달 범위는 TLB 캐시의 항목 수와 페이지 크기가 모두 고려된 TLB 성능을 나타내는 간단한 지표로서,
	    TLB 캐시의 모든 항목이 채워졌을 때 TLB 미스 없이 작동하는 메모리 액세스의 범위로 정의되는데 간단히
		  TLB 항목수 x 페이지 크기로 계산된다.

	 [TLB를 고려한 컨텍스트 스위칭 재정립]
	  
	 - 오늘날 대부분 CPU의 MMU에는 TLB가 들어 있다.
	 - CPU 스케줄링 결과 동일한 프로세스의 다른 스레드가 실행된다면, TLB에 들어있는 항목들이 교체될
	    필요는 없다.
	 - 동일한 프로세스의 주소 공간에서 실행되므로 동일한 페이지 테이블이 사용되기 때문이다.

	 - 하지만, 다른 프로세스의 스레드로 컨텍스트 스위칭되는 경우 CPU는 다른 프로세스의 주소 공간에서 실행하기
	    때문에, TLB는 새로운 프로세스의 페이지 테이블 항목들로 교체되어야 한다.
	 - 컨텍스트 스위칭 과정은 TLB를 고려하면 다음과 같다.

	   1) CPU의 모든 레지스터들을 TCB에 저장한다.
	   2) 새 프로세스의 PCB에 저장된 페이지 테이블의 주소를 CPU 내의 PTBR에 적재한다.
	   3) TLB 캐시의 모든 항목을 지운다. TLB에는 이전 프로세스의 페이지 매핑 정보가 들어가 있기 때문이다.
	   4) 새로 스케줄된 스레드의 TCB에 저장된 레지스터 값들을 CPU에 적재한 후 실행한다. TLB 캐시를
	       비운 채 스레드가 실행되면, TLB 미스가 계속 발행하게 되고 얼마 지나지 않아 TLB 캐시는 새 스레드
		    가 액세스한 페이지 번호와 프레임 번호들로 채워지게 될 것이다. 하지만 이 시간은 무시할 수 없는 시간이다.
























































































































																																																																																																																																											*/