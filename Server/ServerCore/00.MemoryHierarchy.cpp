																																																																																																																																																																																								/*
	   1. 메모리 계층 구조

	- 메모리는 CPU가 실행할 프로그램 코드와 데이터를 저장하는 물리 장치.
	- 메모리에는 실행될 프로그램의 코드와 데이터가 적재되고 실행 중 발생하는 데이터가 저장된다.
	- 기본적으로 CPU는 메모리에 있는 코드와 데이터를 CPU 내부로 읽어 와서 계산하고 결과를 메모리에 저장하기도 함.

	- 컴퓨터 시스템의 모든 기억 공간들을 포괄적으로 메모리라고 할 때, 메모리는 컴퓨터 시스템 내 여러 곳에 배치되어 사용한다.
	
	- 메모리 계층 구조 - 
	 -> CPU 레지스터, 캐시 메모리, 메인 메모리, 보조 기억 장치 등 기억 장치들은 읽기 쓰기의 속도와 용량에 따라
	     계층 구조를 이루는데 이것을 메모리 계층 구조라고 한다.
	 -> CPU 레지스터에서 하드디스크로 갈수록 용량이 커지고, 가격은 싸지며, 읽기쓰기 속도는 느려진다.
	 -> 메모리 계층 구조의 중심에 서 있는 것이 메인 메모리이다.

	   [RAM - 휘발성 장치]
	 - Ram이라고 부르는 반도체 기억 장치가 메모리이며, 하드 디스크는 보조 기억장치이다.
	 - RAM 메모리는 전원이 끊어지면 저장된 정보가 사라지지만 하드 디스크와 같은 보조기억장치의 데이터는 사라지지 않는다.
	 - 하드 디스크가 없는 컴퓨터는 존재할 수 있지만, RMA이 없는 컴퓨터는 존재할 수 없음.


	  [메모리 계층화, 성능과 비용의 절충] - CPU의 메모리 액세스 시간을 줄이기 위함

	- CPU가 명령과 데이터를 가져오는 메모리 액세스 시간을 단축시키기 위해, 메인 메모리보다
	   더 빠른 캐시(off-chip / L3) 메모리를 CPU와 메인 메모리 사이에 설치하여 사용하였다.
	- 캐시 메모리에는 CPU가 현재 실행하는 프로세스의 코드와 데이터 중 당장 실행할 일부를 
	   메인 메모리에서 가져다 놓고 실행하기 위한 메모리이다.
	- 캐시 메모리는 도입된 초기에 CPU 바깥의 컴퓨터 보드 상에 있었고 응답 속도가 빠른 반면
	   가격이 비싸 적은 량만 사용하였다.
	- CPU의 처리 속도는 해마다 발전을 거듭되어 더 빠른 메모리를 필요로 하였고, 그 결과 CPU칩 
	   내부에 캐시 메모리(on-chip 캐시)를 두고 CPU 칩 내에서 코드와 데이터를 액세스함으로써
	    CPU의 메모리 액세스 시간을 단축시켰다.
	- CPU 칩 크기 한꼐로 인해 CPU 내부에 두는 캐시의 크기는 더 제한적일 수밖에 없다.

	- 한편, 컴퓨터의 성능이 좋아지면서 처리할 데이터와 프로그램의 크기도 대형화되고 더 많은 
	   프로세스를 동시에 실행하게 됨으로써, 메인 메모리에 모든 데이터와 코드를 담을 수 없어 
	    하드디스크나 SSD와 같은 대용량이면서 값이 싼 보조 기억 장치를 메인 메모리의 연장된 
		 저장 공간으로 활용하게 되었다.

	  [메모리 계층 구조의 각 요소]

	1) CPU 레지스터들

     - CPU는 현재 실행할 코드와 데이터, 혹은 다음에 실행할 몇 개의 코드와 데이터를 미리 저장할
	    목적으로 레지스터를 가지고 있다.
	 - 레지스터의 크기와 개수는 CPU의 종류에 따라 다르지만, CPU에는 일반적으로 8~30개 정도의 레지스터가 있다.
	 - 레지스터 1개의 크기가 32비트라고 하면, CPU에는 보통 32~120바이트 정도 저장 공간이 있는 셈이다.

	2) 캐시 메모리 (cache memory)

	 - 캐시 메모리는 주기억장치로 사용하고 있는 메인 메모리보다 더 빠른 메모리로서 CPU의 빠른 처리
	    속도에 맞추기 위해 도입되었다.
	 - 캐시 메모리는 메인 메모리보다 가격이 비싸 소량만 사용된다.
	 - 캐시 메모리가 있는 컴퓨터에서는 CPU가 캐시 메모리에서 프로그램 코드와 데이터를 읽어 실행하므로,
	    코드와 데이터들은 메인 메모리에서 캐시 메모리로 미리 복사되어야 한다.
	 - 캐시 메모리는 응답 속도와 위치에 따라 여러 레벨로 나누어 사용된다.
	 - 멀티 코어로 구성된 현대의 CPU에는 코어 별로 L1/L2 이름의 캐시를 두고, 모든 코어들이 공유하는 L3
	    캐시를 두고 있다.
	 - L1/L2 캐시는 CPU 패키지 내에 두지만, L3 캐시는 CPU 외부의 컴퓨터 보드 상에 두거나 Core i7같이 CPU내부에 두기도 함.

	3) 메인 메모리 (RAM - main memory)

	 - 메인 메모리에는 현재 실행 중인 모든 프로세스의 코드와 데이터, 읽거나 쓰고 있는 여러 파일들의
	    블록뿐 아니라 운영체제의 커널 코드와 커널 데이터들이 저장된다.
	 - 캐시 메모리에는 메인 메모리로부터 당장 실행을 위해 필요한 일부분의 코드와 데이터가 복사되는데,
	    사용자 프로그램과 운영체제 커널을 구분하지 않고 복사한다.

	4) 보조기억장치 (secondary memory)

	 - 보조기억장치는 하드 디스크나 SSD와 같이 전원을 꺼도 지워지지 않는 대용량 저장 장치이다
	 - 보조기억장치는 파일이나 데이터베이스 등을 저장할 목적으로 사용되지만, 메인 메모리의 크기 
	    한계로 인해 메모리에 적재된 프로그램 코드와 데이터의 일부를 일시 저장하는 용도로도 사용됨.

     [프로그램의 실행과 메모리 계층 구조]

    1) 응용프로그램의 실행은 운영체제가 보조기억장치에 저장된 실행 파일(exe)을 메인 메모리에
      적재하는 것으로 시작한다.
    2) 메인 메모리에 적재된 코드와 데이터 중 실행할 일부의 코드와 실행에 필요한 데이터가 L3 캐시로 복사됨.
	3) L3 캐시에서 당장 실행할 코드와 데이터의 일부분이 L1/L2 캐시로 복사된다.
	4) CPU 코어는 L1/L2 캐시에서 현재 실행할 명령과 데이터를 레지스터로 읽어 들인 후 연산을 실행.

	 [메인 메모리와 캐시]

	  - CPU가 현재 프로세스나 스레드의 실행을 중단하고 다른 프로세스나 스레드를 실행하게 되면(컨텍스트 스위칭)
	     L1/L2 캐시에는 새로 실행하고자 하는 프로세스나 스레드의 명령과 데이터를 찾을 수 없는 캐시 미스
		  가 발생하고 연쇄적으로 메인 메모리로부터 L3 캐시로, L3캐시에서 L1/L2 캐시로 새 프로세스의
		   코드와 데이터가 이동하게 된다.
	  - 새로운 프로세스나 스레드의 코드와 데이터가 캐시로 들어오기 전에, 현재 캐시에 들어 있는 데이터 중
	     수정된 데이터는 다시 L3 캐시나 메인 메모리에 기록되어야 한다.
	  - 이처럼 캐시로 인해, 프로세스나 스레드의 컨텍스트 스위칭은 코드와 데이터를 이동시키는 보이지 않는
	     오버헤드를 초래함.
	  - 캐시의 크기가 작기 때문에, 캐시 미스는 프로그램의 실행 중에도 발생한다.
	  - CPU가 액세스하는 코드나 데이터가 캐시에 없을 때 발생하며, L3 캐시로부터 필요한 코드와 데이터가
	     L1/L2 캐시로 복사된다. 
	  - 만약 L3 캐시에도 없다면 메인 메모리에서 L3 캐시로, 다시 L3 캐시에서 L1/L2 캐시로 복사된다.

	 [메모리 게층화의 성공 이유, 참조의 지역성(locality of reference)]

	  (메모리를 계층화하면 과연 효율적일까?)
	  - 캐시 메모리는 크기가 작기 때문에 당장 실행할 프로그램의 코드와 데이터를 일부분밖에 둘 수 없다.
	  - CPU가 캐시 메모리에 있는 적은 량의 코드를 실행하고 나면 금방 캐시 미스가 발생하고,
	     다음 코드나 데이터가 캐시로 복사되는 동안 CPU는 기다려야 한다.
	  - CPU의 기다리는 시간이 길거나 캐시 미스가 잦다면, 캐시가 아무리 빠른들 CPU 대기 시간이 길어져서
	     프로그램의 실행 성능이 좋아질 수 있을까?
	  - 아무리 그래도 메모리 계층 구조는 실보다 득이 많다
	 -> 참조의 지역성이라는 일반적인 프로그램 실행 특성에 있다.
	  [정의] : 참조의 지역성이란 코드나 데이터, 자원 등이 아주 짧은 시간 내에 다시 사용되는 프로그램의 특성이다.
	  [예시] : 반복문을 떠 올리면 좋겠다. 캐시 크기가 비록 작지만 하나의 for문 정도는 적재할만하므로,
	            CPU는 for문을 실행하는 상당 시간 동안 캐시에 적재된 코드와 데이터를 액세스하기 때문에,
				 빠른 캐시를 사용함으로써 얻는 이득(다시 사용되므로)이 캐시를 다시 채우기 위해 CPU가 대기하는 실보다 훨씬 크다.

	 
	   2. [메모리 관리]

	   - 메모리는 현재 실행 중인 모든 프로세스들의 코드와 데이터, 그리고 운영체제의 코드와 데이터가
	      적재되어 모든 프로세스들에 의해 사용되는 컴퓨터의 핵심 공유 자원이다. 그러므로 메모리는
		   운영체제에 의해 철저히 관리된다.

     [메모리 관리 이유]
	  - 메모리가 운영체제에 의해 관리되어야 하는 이유를 구체적으로 알아보자.

	1. 메모리는 여러 프로세스에 의해 사용되는 공유 자원이기 때문이다.
	 - 그러므로 프로세스가 마음대로 임의의 메모리 영역을 사용하도록 놓아둘 수 없다.
	 - 이를 위해 운영체제는 프로세스 별로 할당된 메모리 영역과 비어 있는 영역을 관리할 필요가 있다.
	 - 또한 운영체제는 새로운 프로세스가 생성되거나 프로세스가 실행 중 메모리를 필요로 할 때 빈 메모리
	    할당하고, 프로세스의 소멸 시 메모리를 반환하는 등 여러 프로세스가 메모리를 나누어 사용하도록
		 관리할 필요가 있다.

	2. 메모리를 보호하기 위해서이다.
	 - 운영체제는 프로세스에게 할당된 메모리를 다른 프로세스가 접근하지 못하도록 보장할 필요가 있고,
	    또한 사용자 모드에서 커널 공간에 접근하지 못하도록 하는 메몰 보호 기능이 필요하다.
    
	3. 메모리의 용량 한꼐를 극복하기 위해서이다.
	 - 시스템에 설치된 메모리보다 더 많은 메모리를 필요로 하는 큰 프로세스나, 작지만 많은 
	    프로세스들을 동시에 실행시킬 때 메모리가 부족하여 이들을 수용하지 못하는 경우가 발생 할 수 있다.
	 - 운영체제는 이런 경우에도 프로세스들을 정상적으로 실행시킬 수 있는 메모리 관리 기법이 필요하다.
	 - 하드 디스크를 확장된 메모리처럼 사용하여 메모리의 물리적 크기 한계를 극복하는 가상 메모리와 같은
	    메모리 관리 정책이 필요하다.

	4. 메모리 사용의 효율을 높이기 위해서이다.
	 - 다중프로그래밍정도(DOM, Degree of Multiprogramming)란 운영체제가 메모리에 동시에 적재하여 실행시키는
	    프로세스의 개수로서, 운영체제의 메모리 관리 효율성을 나타내는 지표이다. 
	 - 운영체제는 정해진 양의 메모리에 가능하면 많은 프로세스들을 실행시켜 시스템 처리율을 높이는 메모리 관리가 필요.

	[메모리 관리 기능]
	 - 앞서 언급한 메모리 관리 이유로부터 기본적인 메모리 관리 기능은 할당과 보호의 2개로 요약할 수 있다.

	 [1] 메모리 할당
	  - 여러 프로세스들이 컴퓨터 시스템의 메모리를 나누어 사용하도록 프로세스에게 적절히 메모리를 할당하는 기능이다.
	 
	 [2] 메모리 보호
	  - 프로세스가 자신의 영역 외, 다른 프로세스에게 할당된 메모리 영역이나 운영체제 영역을 침범하거나
	     훼손하지 못하도록 보호하는 기능이다.

-------------------------------------------------------------------------------------------------------------------------------------------

     2. 메모리 주소

       [물리주소와 논리 주소]

    - 메모리는 오직 주소를 이용해서만 접근되며 주소는 다음 2가지 형태가 있다.

	[1] 물리 주소 (Physical Address) : 실제 메모리 주소 (하드웨어 주소)
	[2] 가상 주소 (Virtual Address) : 프로그램 내에 사용되는 주소

	-> 물리주소는 물리 메모리(RAM)에 매겨진 주소로서, 컴퓨터를 설계하고 제작하는 시점에 물리
	    메모리에 매겨지는 하드웨어적인 주소이며 0번지부터 시작된다.
    
	- 물리 메모리는 시스템의 내부에 뻗쳐있는 주소버스에 연결되며, CPU 패키지(CPU + MMU) 혹은 CPU 칩으로부터
	   발생된 이진 신호의 물리 주소가 주소 버스에 실려 물리 메모리로 전달된다. MMU는 가상주소를 물리주소로 변환하는 장치
    
	-> 이와 달리 논리 주소는 프로세스 내에서 코드나 데이터(변수나 동적 할당 메모리)의 주소이며 가상 주소와 동일한 의미로 사용됨.

	- 다시 말해 논리 주소는 프로세스가 적재된 물리 메모리와 관계없이 컴파일러에 의해 프로세스 내에서 매겨진 주소.
	- 프로세스의 시작점이 논리 주소 0번지이며 코드나 변수의 주소는 이 주소에 대한 상대 주소이다.
	- 그러므로 논리 주소는 사용자/프로그램 개발자나 프로그램/프로세스에서 사용하는 주소이다.
	- 프로세스 내에서 변수 n이 100번지라고 하면 이것은 논리 주소 100번지라는 뜻이다.
	- 논리 주소는 운영체제가 응용프로그램을 실행시키기 위해 만들어놓은 프로세스 내에서 사용되는 주소이다.

	[논리 주소가 주는 착각]

	 - 논리 주소는 프로세스나 사용자에게 2가지 착각을 준다.
	 [1] 사용자나 프로세스 자신이 모든 메모리를 독점하여 사용하고 있다는 착각
	 [2] 프로세스의 코드와 변수들이 0번지부터 연속적으로 메모리에 적재되어 있다는 착각

	 -> CPU가 프로세스를 실행하는 동안 다루는 모든 주소는 논리 주소이다.
	 -> 모든 프로세스는 실행될 때마다 다른 물리 주소에 적재되지만, 프로세스 내에 적재된 코드와 변수
	     의 논리 주소는 항상 동일하다. (큰의미 중요!)
	 -> 커널 역시 논리 주소로 이루어져 커널 코드가 실행될 때도 논리 주소가 물리 주소로 바뀌어야 한다.

	[논리 주소의 물리 주소 변환] - 매핑 테이블은 프로세스마다 다름

	 - 메모리를 액세스하기 위해서는 논리 주소가 물리 주소로 바뀌어, 물리 주소가 물리 메모리에 전달되어야 한다.

	 1) mov ax, [4] - 4번지(논리주소)의 데이터를 읽어 레지스터 ax에 저장하라는 명령

	   - CPU가 이 명령을 실행하기 위해 논리 주소 4번지를 발생시키면, 주소 변환 하드웨어(MMU)에
	      의해 물리 주소로 변환되고 이 주소가 CPU 패키지 밖으로 빠져나가 물리 메모리에 전달된다.
	   
	   [주소 변환 하드웨어] - MMU(Memory Management Unit)으로도 부릴고 CPU 패키지 내에 구성
	    -MMU는 프로세스의 논리 주소와 물리 주소의 매핑 정보를 담은 매핑 테이블을 참고하여 논리 주소를
		  물리 주소로 변환한다.


	[컴파일과 논리 주소]

	 - 컴파일러는 사용자가 작성한 프로그램을 논리 주소로 컴파일한다.
	 - 컴파일 시점에서 응용프로그램이 물리 메모리 몇 번지에 적재될 지 알 수 없기 때문에 물리 주소로
	    컴파일하는 것은 애초에 불가능하다.
	 - 그러므로 컴파일 후 생성된 실행 파일 내에 모든 코드와 변수들은 논리 주소로만 구성된다.

	 - 프로그램이 실행을 시작할 때, 운영체제는 프로세스를 생성하고 실행 파일로부터 코드와 데이터 등을 
	    적절한 물리 메모리에 적재한 후, 프로세스 별로 코드와 데이터가 적재된 물리 주소의 매핑 테이블을 
		 만들어 놓는다.
	 - MMU는 이 매핑 테이블을 이용하여 CPU로 부터 출력된 논리 주소를 물리 주소로 바꾼다.
	 - 매핑 테이블과 MMU 덕분에 컴파일러는 프로그램을 논리 주소로 컴파일하는데 부담이 없고, 운영체제
	    역시  프로세스의 코드와 데이터를 물리 메모리의 빈 곳 아무데나 적재되어도 문제가 발생하지 않는다.
	 - 프로그램 개발자 역시 응용프로그램이 물리 메모리 몇 번지에 적재될지 몰라도 된다. 사실 알 수도 없다.
	 - CPU도 현재 실행하는 명령이 물리 메모리 몇 번지에 있는지 알지 못한다. 오직 MMU만 알고있다.

	  번외) ASLR(Address Space Layout Randomization) 
	   -> 해커들의 공격을 어렵게 하기 위해 프로세스의 주소 공간 내에서 스택이나 힙, 라이브러리 영역을
	       랜덤으로 배치하여 실행할 때마다 이들의 논리 주소가 바뀌게 하는 기법이며, 오늘날 대부분의 운체에서 사용.
	   -> 프로세스의 코드와 데이터 영역은 크기와 위치가 고정되어 프로그램이 실행될 때마다 코드와 전역 변수의
	       주소(논리 주소)는 동일하지만
	   -> ASLR 기법에 의해 동적할당되는 주소와 스택에 만들어지는 지역변수의 주소는 실행 시킬 때마다 다르게 나온다..

-------------------------------------------------------------------------------------------------------------------------------------------

	 3. 물리 메모리 관리
	 
	  - 컴퓨터 시스템 내에 설치된 메모리는 여러 프로세스들이 적재되고 실행되면서 공동으로 활용되는 실존 공간이다.
	  - 그래서 물리 메모리라고 부른다.
	  - 운영체제는 제한된 물리 메모리에서 여러 프로세스들이 실행되도록 잘 관리해야 한다.
	  
	 [메모리 할당 - memory allocation]

	  - 메모리 할당이란 운영체제가 새 프로세스를 실행시키거나 실행중인 프로세스가 메모리를 필요로 할 때 물리 메모리를 할당함.
	  - 구체적으로 프로세스의 코드와 데이터를 적재하기 위해 물리 메모리 공간이 할당되고, 프로세스의 실행 중
	     동적으로 스택이나 힙을 사용할 때 필요한 물리 메모리 공간이 할당되는데, 메모리 할당은 전적으로
		  운영체제 커널에 의해 이루어진다.
	  
	                                   메모리 할당 기법
	                                        /   \
								연속 메모리 할당  분할 메모리 할당
								/                              \
	고정 크기 할당(paging) or 가변 크기 할당(segmentation)    가변 크기 할당  or 고정 크기 할당




	 [연속 메모리 할당] - 고전 방식

	  - 연속 메모리 할당(contiguous memory allocation) 은 각 프로세스에게 메모리 한 덩어리 (single contiguos memry)
	     씩 할당하는 기법이다.
	  - 여기서 연속이라는 뜻은 프로세스가 할당받은 메모리가 한 덩어리로 연속된 공간이라는 의미이다.
	  - 연속 메모리 할당은 다시 2가지로 분류되는데, 메모리 전체를 파티션(partition)으로 불리는 고정 크기로 나누고
	     프로세스마다 1개의 파티션을 할당하는 고정 크기 할당(fixed size partition allocation)과,
		  프로세스마다 프로세스 크기의 메모리를 할당하는 가변 크기 할당(variable size partition allocation)이 있다.
	  - 가변 크기 할당은 프로세스의 크기가 서로 다르기 때문에 할당하는 크기도 달라 붙여진 이름.
	  - 가변 크기 할당에서 파티션도 가변 크기이다.
	  - 고정 크기의 파티션(모두 같게)은 프로세스마다 고유로 할당하는 크기이고 거기 내에 프로세스마다 해당 크기의 메모리를
	     할당하는게 가변 크기 할당.
	  


	 [분할 메모리 할당 - non contiguos memroy allocation]
	  
	  - 연속 메모리 할당은 프로세스에게 하나의 연속된 메모리를 할당하므로 메모리 할당의 유연성이 부족하다.
	  - 메모리 전체에 비어 있는 작은 공간(홀)들을 합하면 충분한 공간이 있음에도 불구하고, 프로세스를 적재할
	     만큼의 연속된 메모리가 없어 프로세스를 적재할 수 없는 경우가 발생한다.
	  -> 연속 메모리 할당의 이런 단점을 해결하기 위해 분할 메모리 할당 기법이 제안되었다.

	  분할 메모리 할당은 프로세스에게 필요한 메모리를 여러 덩어리로 나누어 분산 할당하는 방법으로
	  [1] 가변 크기 할당 - 세그멘테이션 : 프로세스에게 크기가 다른 여러개의 덩어리 메모리 할당
	  [2] 고정 크기 할당 - 페이징 : 프로세스마다 동일한 크기의 덩어리를 여러개 할당
	  으로 나뉜다.

	 [세그멘테이션] - 논리적인 의미있는 세그먼트의 해당 크기로 분할 / 각 세그먼트 크기 다름
	  - 새그멘테이션 기법에서는 프로세스를 여러 개의 논리적인 덩어리로 분할하고 각 덩어리를 세그멘트라고 부른다.
	  - 세그먼트는 프로세스 내에서 하나의 단위로 다룰 수 있는 의미있는 블록이다.
	  - 예를 들어 함수가 하나의 세그먼트가 될 수 있고, 객체가 하나의 세그먼트가 될 수 있다.
	  - 프로세스를 구성하는 각 세그먼트들의 크기가 다를 수밖에 없다.
	  - 세그멘테이션 기법은 프로세스를 구성하는 세그먼트들을 동일한 크기로 물리 메모리에 분산 할당한다.
	  - 세그먼테이션을 지원하는 대부분의 시스템에서는 프로세스를 코드, 데이터, 스택, 힙의 4개 세그먼트로 분할하고 할당하는 방법 사용.

	 [페이징] - 동일 크기의 page로 분할 / 각 페이지 크기 같음
	 - 페이징 기법은 프로세스를 논리적인 단위로 분할하지 않고, 논리주소 0번지부터 page라고 부르는 고정 크기로 분할한다.
	 - 물리 메모리 역시 페이지와 동일한 크기로 분할하여 프레임(frame)이라고 부르며 프로세스의 각
	    페이지를 물리 메모리의 프레임에 하나씩 분산 할당한다.




	[연속 메모리 할당]

	 - 연속 메모리 할당은 프로세스에게 1개의 연속된 메모리 블록을 할당하는 기법으로 초기 운영체제
	    에서 사용하였지만 지금은 사용되지 않으며 분할 할당의 세그먼테이션과 페이징 혼합으로 사용됨.
	 - 예전 MS-DOS는 단일사용자 단일 프로세스만 지원하였기 때문에 현재 실행중인 프로세스가 전체 메모리를
	    하나의 연속된 저장 공간으로 독점 사용해왔다.
     
	 [1] 연속 메모리 할당 - 고정 크기 할당 방식

	   - 고정 크기 할당 기법은 메모리를 파티션이라는 동일한 고정 크기로 나누고, 프로세스에게 1개의
	      파티션을 할당하는 단순한 기법이다.
	   - 메모리 전체를 n개의 파티션으로 분할하고 프로세스를 실행 시킬 때 각 프로세스에게 1개의 파티션을 할당한다.
	   - 동시에 실행시킬 수 있는 프로세스의 개수를 n개로 제한하여 n개의 프로세스가 실행되고 있을 때 새로운
	      프로세스가 도착하면 프로세스 하나가 종료될 때까지 작업 큐에서 대기한다.
	   
	   [문제점]
	   - 고정 크기 할당은 프로세스가 파티션의 크기보다 작은 경우 메모리의 일부가 낭비됨.
	   - 파티션 크기보다 큰 프로세스는 처음부터 실행될 수 없는 문제가 있음.
	   - 이 문제는 시스템 운영자가 실행시킬 전체 응용프로그램들의 크기를 사전에 계산하여 파티션 크기를
	      정하는 방식으로 개선되었다.

	 [2] 연속 메모리 할당 - 가변 크기 할당
	   
	   - 고정 크기 할당은 프로세스의 크기가 파티션의 크기보다 항상 작기 때문에 파티션 내에 사용되지 않는
	      메모리 낭비가 발생한다.
	   - 이러한 메모리 낭비를 줄이고 고정 개수의 프로세스를 실행시킬 수 밖에 없는 한계를 해결하고자 
	      가변 크기 할당이 제시되었다.
	   - 가변 크기 할당 기법은 프로세스의 크기가 모두 다른 것을 고려하여 각 프로세스에게 프로세스와 동일한
	      크기의 메모리를 할당한다.(중요!)
	   -> 가변 크기 할당을 사용하면 수용 가능한 프로세스의 개수는 가변적이다.
	   -> 프로세스가 도착하였을 때 가용 메모리가 부족하면, 실행 중인 프로세스가 종료되어 필요한만큼
	       가용 공간이 생길 때까지 작업 큐에서 대기한다.




    [단편화 - fragmentation] - Hole 위치에 따라 내부(internal)/외부(external) 단편화

	 - 단편화란 프로세스에게 할당할 수 없는 작은 크기의 조각 메모리들이 생기는 현상이다.
	 - 조각 메모리를 홀이라고 부르며 홀이 너무 작아 프로세스에게 할당할 수 없을 때 단편화가 발생
	 - 단편화는 홀이 생기는 위치에 따라 내부 단편화와 외부 단편화로 나뉜다.
	 - 연속 메모리 할당 뿐 아니라 어떤 메모리 할당 정책을 사용해도 단편화는 발생하므로, 단편화로
	    인한 메모리 낭비를 줄이는 메모리 할당 정책이 좋은 정책이라 할 수 있다.

	[1] 내부 단편화 - internal fragmentation -> 고정 크기 할당의 경우

      - 내부 단편화는 프로세스에게 할당된 메모리 영역 내에 활용할 수 없는 홀이 생기는 경우이다.
	  - 내부 단편화는 고정 크기 파티션에서 볼 수 있다.

	  -> 고정 크기의 경우 고정으로 파티션 크기를 정하여 할당하므로 파티션보다 크기가 작은 프로세스 메모리가
	      적재되면 빈 홀들이 생겨 그 메모리들이 낭비되어 모든 파티션이 차면 메모리가 비어있음에도 불구하고
		   프로ㅔㅅ스가 새로 적재되지 못함.

	[2] 외부 단편화 - external fragmentation -> 가변 크기 할당의 경우

	 - 외부 단편화는 할당된 메모리들 사이에 활용할 수 없는 홀이 생기는 경우이다.
	 - 가변 크기 파티션의 경우 외부 단편화가 나타난다
	 - 크기가 다른 파티션이 할당되고 반환되기를 반복하면서 파티션과 파티션 사이의 홀이 발생하는데,
	    그 중 어떤 홀들은 너무 작아 프로세스에게 할당할 수 없는 단편화를 초래한다.
	 - 외부 단편화로 인해 할당할 메모리가 부족해지면, 파티션을 이동시켜 홀을 없애는 메모리 압축 기법을
	    사용할 수 있다 (memory compaction)
	 
	  나의 고찰)
	  - 분할 할당의 페이징을 사용하면 page(고정 크기)로 관리하니까 외부 단편화는 없겠지만, 
	     페이지 크기보다 실제 사용 메모리가 적으면 내부 단편화 발생(페이지 내의 빈 공간은 페이지 독점이라 따로 낑겨넣을수도 없음)..
      - 분할 할당의 세그멘테이션을 사용하면 세그먼트(가변 길이)로 관리하니까 내부 단편화는 없겠지만,
	     세그먼트 사이에 빈 공간으로 인한 외부 단편화 발생.



     [연속 메모리 할당 구현] - 고전 방식

	  - 고정 크기 할당이든 가변 크기 할당이든 상관없이 연속 메모리 할당을 구현하기 위해서는 하드웨어와 운영체제 지원이 필요함.

	  [1] 하드웨어 지원
	   - 연속 메모리 할당을 구현하기 위해, 하드웨어적으로는 프로세스의 실행 중에 논리 주소를 물리 주소로 변환하는 기능과
	      프로세스가 다른 프로세스의 메모리 액세스를 금지하는 기능이 구현되어야 한다.
	   - 이 기능들을 구현하기 위해 cpu에는 다음 레지스터들이 필요하다.
	    -> base 레지스터 : 현재 실행 중인 프로세스에게 할당된 물리 메모리 시작 주소
		-> limit 레지스터 : 현재 실행 중인 프로세스에게 할당된 메모리 크기
		-> 주소 레지스터 : 현재 액세스하는 메모리의 논리 주소
	   - 그리고 MMU 가 필요하다.

	   ex) base 레지스터에 1000이라는 값이 들어있고 이는 시작 물리 주소이다(물리 메모리에서)
	       limit 레지스터에는 800이라는 값이 있으면 물리 메모리에서 1000~1800이 해당 프로세스에게 할당된 메모리임을 알 수 있음.
		   주소 레지스터에는 300이라는 값이 있으면 현재 실행할 코드나 데이터가 1300의 위치에 있는지 알 수 있고,
		    이 과정에서 300이 limit 레지스터 값보다 큰지 판단하여 액세스 접근 권한을 줌.
	  
	  [2] 운영체제 지원
	   - 운영체제는 연속 메모리 할당을 위해 모든 프로세스에 대해 프로세스별로 할당된 물리 메모리의 시작 주소와
	      크기 정보를 저장 관리하고 비어 있는 메모리 영역을 관리해야 한다.
	   - 그리고 새 프로세스를 스케줄링하여 실행시킬 때마다, 프로세스의 물리 메모리의 시작 주소와 크기 정보를
	      CPU 내부의 base 레지스터와 limit 레지스터에 적재시켜야 한다.


	 [홀 선택 알고리즘/동적 메모리 할당]

	  - 프로세스가 실행되고 종료하는 과정을 거치면서 메모리가 할당되고 반환되기를 반복하며, 이 과정에서
	    메모리에는 할당된 영역 사이에 홀들이 생긴다.
	  - 운영체제는 프로세스를 처음 실행시키거나 프로세스의 실행 도중 메모리가 요구될 때, 적당한 홀을 선택
	     해서 할당해야 하는데 이를 홀 선택  알고리즘 혹은 동적 메모리 할당이라고 하낟.

	  - 고정 크기 할당 시 홀 선택 알고리즘은 단순하다. 운영체제는 홀(파티션)들을 가용 메모리 리스트로 만들어
	     관리하고 여기서 하나를 선택하면 된다.
	  - 하지만 가변 크기 할당을 사용한다면, 운영체제는 메모리 전체에 걸쳐 비어있는 영역, 즉 홀마다
	     시작 주소와 크기 정보를 구성하고, 이들을 홀리스트로 만들고 관리해야 한다.
	  - 그리고 메모리 할당 요청이 발생하면 홀 리스트에서 적절한 홀을 선택해야 한다.
	  - 어떤 홀을 선택하느냐에 따라 성능이 달라지는데 다음은 대표적인 3가지 홀 선택 알고리즘이다.
	   [1] first-fit
	     - first-fit은 홀 리스트를 검색하여 처음으로 만나는, 요청 크기보다 큰 홀을 선택한다. 
		 - 알고리즘의 속도는 빠르지만, 외부 단편화로 인한 메모리 낭비가 크다.(요청 크기보다 커서)
	   
	   [2] best-fit
	     - best-fit은 홀 리스트를 검색하여, 요청 크기를 수용하는 것 중 가장 작은 홀을 선택한다.
		 - 그 결과 할당된 메모리 영역(홀) 내에 가장 작은 홀이 새로 생긴다.
		 - best-fist의 경우 홀 리스트가 크기 별로 정렬되어 있지 않으면 홀을 전부 검색해야 하는 부담.
		 - 대신 외부 단편화의 크기가 작아 메모리 낭비 줄일 수 있음.
	   
	   [3] worst-fit
		 - worst-fit 은 홀 리스트를 검색하여, 요청 크기를 수용하는 것 중 가장 큰 홀을 선택한다.
		 - 그 결과 새로 할당된 메모리 영역(홀) 내에 가장 큰 홀이 새로 생긴다.
		 - 이 방법 역시 홀 리스트가 크기 별로 정렬되어 있지 않으면 홀을 전부 검색해야 하는 부담이 있음.
		 - 외부 단편화 크기가 커 메모리 낭비가 심하여 worst임.

	  [연속 메모리 할당의 장단점 - 과거에 쓰인 기법]

	    [장점]
	   - 연속 메모리 할당은 메모리 할당 알고리즘이 단순하여 구현이 용이하다.
	   - 논리 주소를 물리 주소로 바꾸는 과정이 단순하여 CPU가 메모리를 액세스하는 속도가 상대적으로 빠름
	   - 분할 메모리 할당에서 프로세스에게 할당된 여러 분할 메모리 영역을 관리하는 부담에 비하면,
	      프로세스마다 할당된 물리 메모리 영역을 관리하기 위해 물리 메모리의 시작위치와 크기정보만 관리하면
		   되므로 운영체제의 부담이 덜하다
  
        [단점]
	  - 연속 메모리 할당은 프로세스에게 하나의 연속된 메모리를 할당하므로 메모리 할당의 유연성이 부족함.
	  - 작은 홀들을 합하면 메모리에 충분한 공간이 있음에도 불구하고 프로세스에게 연속된 메모리 공간을 할당할 수 없음.
	  - 홀들을 한쪽으로 모아 큰 빈 메모리 공간을 만드는 메모리 압축이 고려될 수 있음
	  - 만일 처음부터 프로세스에게 필요한 메모리를 예측하여 큰 메모리를 할당한다면 내부 단편화를 초래함.


--------------------------------------------------------------------------------------------------------------------------------------

		5. 세그먼테이션 메모리 관리

		 [세그먼테이션의 개요]

		- 세그먼테이션 메모리 관리 기법에서 프로세스를 구성하는 논리 블록을 세그먼트라 부른다.
		- 세그먼테이션 메모리 관리 기법은 프로세스를 논리 세그먼트들로 나누고 각 논리 세그먼트에
		   한 덩어리의 물리 메모리를 할당하는 정책이다.
		- 이 물리 메모리 덩어리를 물리 세그먼트라고 부르며 크기는 서로 다르다.

		- 운영체제마다 세그먼트를 서로 다르게 구성할 수 있지만 역사적으로 세그먼테이션을 사용하는 운영체제는
		   다음과 같이 나누어 왔다.

		   1) 코드 세그먼트 : 프로그램 전체에 걸쳐 작성된 모든 코드들
		   2) 데이터 세그먼트 : 프로그램 전체에 걸쳐 선언된 전역 변수들과 정적 변수
		   3) 스택 세그먼트 : 함수가 호출될 때 지역변수나 매개 변수, 리턴값들을 저장하는 메모리 공간
		   4) 힙 세그먼트 : 프로세스 실행 중에 동적으로 할당받는 메모리 영역
		
		- 프로그램이 실행될 때, 운영체제의 로더는 실행 파일 내에 구성되어 있는 각 논리 세그먼트에 대해
		   물리 메모리에서 동일한 크기로 물리 세그먼트를 할당하고, 논리 세그먼트를 물리 세그먼트에 적재한다.
	    - 그리고 운영체제는 프로세스 실행 시 필요한 크기의 스택 세그먼트와 동적 할당을 위한 힙 세그먼트를 물리메모리에 할당.

		[논리 세그먼트와 물리 세그먼트의 매핑]

		 - 세그먼테이션 기법을 사용하는 운영체제는 프로세스의 각 논리 세그먼트가 할당된 물리 메모리의 위치를
		    관리하기 위해 세그먼트 테이블을 구성한다(논리 세그먼트 -> 물리 세그먼트 매핑을 위해)
		 - 세그먼트 테이블은 프로세스 별로 둘 수도 있지만, 프로세스 당 세그먼트의 개수가 작기 때문에
		    시스템 전체에 1개의 세그먼트 테이블을 이용하여 현재 적재된 모든 프로세스들의 세그먼트들을 관리한다.
	     - 세그먼트 테이블의 항목은 논리 세그먼트가 적재된 세그먼트의 시작 물리 주소(base)와 세그먼트의 크기로(limit)
		    구성되고, 세그먼트 테이블에는 현재 실행 중인 모든 프로세스에 대해 논리 세그먼트 당 하나의 항목이 저장된다.
		 - 프로세스가 실행되고 사라지는 과정이 반복되면 자연스럽게 물리 메모리에 물리 세그먼트들 사이에 홀이 생기며,
		    작은 홀들로 인해 외부 단편화가 초래된다.
	     - 또한, 새로운 프로세스가 실행되면 운영체제는 프로세스의 각 세그먼트를 적재할 빈 홀을 찾기 위해서
		    홀 선택 알고리즘을 사용한다.


			- 현대 운영체제에서는 세그멘테이션(segmentation)은 사실상 안 쓴다.
			- 현대 OS는 대부분 순수한 페이징(Paging) 기반으로 동작한다.
					단점	             설명
			외부 단편화 발생	가변 크기 세그먼트가 흩어짐
			관리 복잡성	세그먼트 추가/삭제 어려움
			가상 메모리와 충돌	세그먼트 + 페이징 복합 구조가 불편

				페이징이 모든 문제를 해결해버림
					문제	페이징으로 해결됨
				외부 단편화	페이지는 고정 크기, 외부 단편화 없음
				동적 확장 어려움	페이지를 붙이면 됨, 비연속 OK
				보호	페이지 단위로 보호 가능, 접근 권한 세부 설정 가능
				주소 공간 관리 복잡	MMU가 페이지 테이블로 자동 관리

--------------------------------------------------------------------------------------------------------------------------------------------

        






































































																																																																																																																																																																										*/